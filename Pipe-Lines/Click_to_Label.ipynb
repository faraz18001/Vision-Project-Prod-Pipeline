{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Click-to-Label: SAM-Powered Manual Annotation\n",
                "\n",
                "**Purpose**: Label ANY object (even new classes like Hammer) by clicking on it.\n",
                "\n",
                "**How it works**:\n",
                "1. Upload your images.\n",
                "2. Click on objects in each image.\n",
                "3. SAM automatically segments the clicked object.\n",
                "4. Type the class name.\n",
                "5. Download YOLO-format labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install Dependencies\n",
                "!pip install segment-anything opencv-python-headless\n",
                "!pip install ipywidgets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Upload Images\n",
                "import os\n",
                "import zipfile\n",
                "from google.colab import files\n",
                "\n",
                "os.makedirs(\"input_images\", exist_ok=True)\n",
                "os.makedirs(\"output_labels\", exist_ok=True)\n",
                "\n",
                "IMAGES_DIR = \"input_images\"\n",
                "LABELS_DIR = \"output_labels\"\n",
                "\n",
                "print(\"--- UPLOAD IMAGES ---\")\n",
                "print(\"Upload a ZIP of images OR individual image files.\")\n",
                "\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    if filename.endswith('.zip'):\n",
                "        with zipfile.ZipFile(filename, 'r') as z:\n",
                "            z.extractall(IMAGES_DIR)\n",
                "        print(f\"Extracted zip to {IMAGES_DIR}\")\n",
                "    else:\n",
                "        os.rename(filename, os.path.join(IMAGES_DIR, filename))\n",
                "        print(f\"Moved {filename} to {IMAGES_DIR}\")\n",
                "\n",
                "# List images\n",
                "image_files = []\n",
                "for root, dirs, fnames in os.walk(IMAGES_DIR):\n",
                "    for f in fnames:\n",
                "        if f.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
                "            image_files.append(os.path.join(root, f))\n",
                "\n",
                "print(f\"Found {len(image_files)} images.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Load SAM Model\n",
                "import torch\n",
                "from segment_anything import sam_model_registry, SamPredictor\n",
                "\n",
                "SAM_CHECKPOINT = \"sam_vit_h_4b8939.pth\"\n",
                "if not os.path.exists(SAM_CHECKPOINT):\n",
                "    print(\"Downloading SAM checkpoint...\")\n",
                "    !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
                "    print(\"Downloaded!\")\n",
                "\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {DEVICE}\")\n",
                "\n",
                "sam = sam_model_registry[\"vit_h\"](checkpoint=SAM_CHECKPOINT)\n",
                "sam.to(device=DEVICE)\n",
                "predictor = SamPredictor(sam)\n",
                "print(\"SAM Model Loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Interactive Click-to-Label\n",
                "import cv2\n",
                "import numpy as np\n",
                "from google.colab.patches import cv2_imshow\n",
                "from google.colab import output\n",
                "\n",
                "# Store all labels\n",
                "all_labels = {}  # {image_path: [(class_name, x_center, y_center, width, height), ...]}\n",
                "class_names = set()  # Track all unique class names\n",
                "\n",
                "def get_bounding_box_from_mask(mask):\n",
                "    \"\"\"Convert a binary mask to YOLO format bounding box.\"\"\"\n",
                "    rows = np.any(mask, axis=1)\n",
                "    cols = np.any(mask, axis=0)\n",
                "    \n",
                "    if not np.any(rows) or not np.any(cols):\n",
                "        return None\n",
                "    \n",
                "    y_min = np.where(rows)[0][0]\n",
                "    y_max = np.where(rows)[0][-1]\n",
                "    x_min = np.where(cols)[0][0]\n",
                "    x_max = np.where(cols)[0][-1]\n",
                "    \n",
                "    return x_min, y_min, x_max, y_max\n",
                "\n",
                "def label_image(img_path):\n",
                "    \"\"\"Label a single image interactively.\"\"\"\n",
                "    image = cv2.imread(img_path)\n",
                "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "    h, w = image.shape[:2]\n",
                "    \n",
                "    predictor.set_image(image_rgb)\n",
                "    \n",
                "    labels_for_image = []\n",
                "    display_image = image.copy()\n",
                "    \n",
                "    print(f\"\\n--- Labeling: {os.path.basename(img_path)} ---\")\n",
                "    print(\"Image size:\", w, \"x\", h)\n",
                "    cv2_imshow(display_image)\n",
                "    \n",
                "    while True:\n",
                "        print(\"\\nEnter click coordinates (x y) or 'done' to finish this image:\")\n",
                "        user_input = input().strip()\n",
                "        \n",
                "        if user_input.lower() == 'done':\n",
                "            break\n",
                "        \n",
                "        try:\n",
                "            parts = user_input.split()\n",
                "            click_x = int(parts[0])\n",
                "            click_y = int(parts[1])\n",
                "        except:\n",
                "            print(\"Invalid input. Use format: x y (e.g., 150 200)\")\n",
                "            continue\n",
                "        \n",
                "        # Run SAM prediction\n",
                "        input_point = np.array([[click_x, click_y]])\n",
                "        input_label = np.array([1])  # 1 = foreground\n",
                "        \n",
                "        masks, scores, _ = predictor.predict(\n",
                "            point_coords=input_point,\n",
                "            point_labels=input_label,\n",
                "            multimask_output=True,\n",
                "        )\n",
                "        \n",
                "        # Use the best mask\n",
                "        best_idx = np.argmax(scores)\n",
                "        mask = masks[best_idx]\n",
                "        \n",
                "        # Get bounding box\n",
                "        bbox = get_bounding_box_from_mask(mask)\n",
                "        if bbox is None:\n",
                "            print(\"No object found at that location.\")\n",
                "            continue\n",
                "        \n",
                "        x_min, y_min, x_max, y_max = bbox\n",
                "        \n",
                "        # Draw on display image\n",
                "        color = (0, 255, 0)\n",
                "        cv2.rectangle(display_image, (x_min, y_min), (x_max, y_max), color, 2)\n",
                "        cv2.circle(display_image, (click_x, click_y), 5, (255, 0, 0), -1)\n",
                "        \n",
                "        # Show updated image\n",
                "        output.clear()\n",
                "        print(f\"--- Labeling: {os.path.basename(img_path)} ---\")\n",
                "        cv2_imshow(display_image)\n",
                "        print(f\"\\nDetected box: ({x_min}, {y_min}) to ({x_max}, {y_max})\")\n",
                "        \n",
                "        # Ask for class name\n",
                "        print(\"Enter class name for this object:\")\n",
                "        class_name = input().strip()\n",
                "        \n",
                "        if class_name:\n",
                "            # Convert to YOLO format (normalized)\n",
                "            x_center = ((x_min + x_max) / 2) / w\n",
                "            y_center = ((y_min + y_max) / 2) / h\n",
                "            box_w = (x_max - x_min) / w\n",
                "            box_h = (y_max - y_min) / h\n",
                "            \n",
                "            labels_for_image.append((class_name, x_center, y_center, box_w, box_h))\n",
                "            class_names.add(class_name)\n",
                "            \n",
                "            # Draw label text\n",
                "            cv2.putText(display_image, class_name, (x_min, y_min - 10), \n",
                "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
                "            \n",
                "            print(f\"Added: {class_name}\")\n",
                "    \n",
                "    return labels_for_image\n",
                "\n",
                "print(\"Ready to start labeling!\")\n",
                "print(f\"You have {len(image_files)} images to label.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 5: Label All Images\n",
                "# Run this cell to start the labeling process\n",
                "\n",
                "for img_path in image_files:\n",
                "    labels = label_image(img_path)\n",
                "    all_labels[img_path] = labels\n",
                "    print(f\"\\nLabeled {len(labels)} objects in {os.path.basename(img_path)}\")\n",
                "\n",
                "print(\"\\n=== LABELING COMPLETE ===\")\n",
                "print(f\"Total images labeled: {len(all_labels)}\")\n",
                "print(f\"Classes found: {class_names}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 6: Export YOLO Labels\n",
                "import shutil\n",
                "\n",
                "# Create class mapping\n",
                "class_list = sorted(list(class_names))\n",
                "class_to_id = {}\n",
                "for i in range(len(class_list)):\n",
                "    class_to_id[class_list[i]] = i\n",
                "\n",
                "# Write classes.txt\n",
                "with open(os.path.join(LABELS_DIR, \"classes.txt\"), \"w\") as f:\n",
                "    for c in class_list:\n",
                "        f.write(c + \"\\n\")\n",
                "\n",
                "# Create images folder in output\n",
                "out_images = os.path.join(LABELS_DIR, \"images\")\n",
                "out_labels = os.path.join(LABELS_DIR, \"labels\")\n",
                "os.makedirs(out_images, exist_ok=True)\n",
                "os.makedirs(out_labels, exist_ok=True)\n",
                "\n",
                "# Write label files\n",
                "for img_path, labels in all_labels.items():\n",
                "    if len(labels) == 0:\n",
                "        continue\n",
                "    \n",
                "    filename = os.path.basename(img_path)\n",
                "    base_name = os.path.splitext(filename)[0]\n",
                "    \n",
                "    # Copy image\n",
                "    shutil.copy(img_path, os.path.join(out_images, filename))\n",
                "    \n",
                "    # Write labels\n",
                "    label_path = os.path.join(out_labels, base_name + \".txt\")\n",
                "    with open(label_path, \"w\") as f:\n",
                "        for class_name, x_c, y_c, w, h in labels:\n",
                "            class_id = class_to_id[class_name]\n",
                "            f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
                "\n",
                "print(f\"Exported {len([l for l in all_labels.values() if len(l) > 0])} labeled images.\")\n",
                "print(f\"Classes: {class_list}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 7: Download Results\n",
                "!zip -r click_labels.zip output_labels\n",
                "\n",
                "from google.colab import files\n",
                "files.download('click_labels.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}