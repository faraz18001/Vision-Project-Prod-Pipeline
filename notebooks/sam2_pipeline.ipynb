{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SAM 2 Auto-Segmentation Pipeline\n",
                "\n",
                "Uses YOLO for detection + SAM 2 for precise segmentation masks.\n",
                "\n",
                "**Note:** SAM 2 requires GPU. Run this on Colab/Kaggle with GPU enabled."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install dependencies\n",
                "!pip install ultralytics\n",
                "!pip install git+https://github.com/facebookresearch/sam2.git"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Set paths\n",
                "\n",
                "PROJECT_ROOT = \"c:/Users/Tesla Laptops/Videos/Construction-Site-Safety-PPE-Detection\"\n",
                "\n",
                "# Your trained YOLO model for detection\n",
                "YOLO_MODEL = f\"{PROJECT_ROOT}/models/best.pt\"\n",
                "\n",
                "# Input images folder\n",
                "INPUT_IMAGES = f\"{PROJECT_ROOT}/new_images\"\n",
                "\n",
                "# Output folder for masks\n",
                "OUTPUT_FOLDER = f\"{PROJECT_ROOT}/sam_outputs\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Load models\n",
                "import torch\n",
                "from ultralytics import YOLO\n",
                "from sam2.build_sam import build_sam2\n",
                "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
                "\n",
                "# Check GPU\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Load YOLO\n",
                "yolo_model = YOLO(YOLO_MODEL)\n",
                "print(f\"YOLO classes: {yolo_model.names}\")\n",
                "\n",
                "# Load SAM 2 (will download checkpoint automatically)\n",
                "sam2_checkpoint = \"facebook/sam2-hiera-large\"\n",
                "sam2_model = build_sam2(sam2_checkpoint)\n",
                "predictor = SAM2ImagePredictor(sam2_model)\n",
                "print(\"SAM 2 loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Run YOLO + SAM pipeline\n",
                "import os\n",
                "import cv2\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "\n",
                "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
                "os.makedirs(f\"{OUTPUT_FOLDER}/masks\", exist_ok=True)\n",
                "os.makedirs(f\"{OUTPUT_FOLDER}/visualizations\", exist_ok=True)\n",
                "\n",
                "# Get all images\n",
                "image_files = []\n",
                "for ext in ['jpg', 'jpeg', 'png']:\n",
                "    for f in os.listdir(INPUT_IMAGES):\n",
                "        if f.lower().endswith(ext):\n",
                "            image_files.append(f)\n",
                "\n",
                "print(f\"Found {len(image_files)} images\")\n",
                "\n",
                "for img_file in image_files:\n",
                "    img_path = os.path.join(INPUT_IMAGES, img_file)\n",
                "    image = cv2.imread(img_path)\n",
                "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Run YOLO detection\n",
                "    results = yolo_model.predict(image_rgb, verbose=False)[0]\n",
                "    boxes = results.boxes.xyxy.cpu().numpy()\n",
                "    \n",
                "    if len(boxes) == 0:\n",
                "        print(f\"{img_file}: No detections\")\n",
                "        continue\n",
                "    \n",
                "    # Run SAM 2 with YOLO boxes as prompts\n",
                "    predictor.set_image(image_rgb)\n",
                "    \n",
                "    all_masks = []\n",
                "    for box in boxes:\n",
                "        masks, scores, _ = predictor.predict(\n",
                "            box=box,\n",
                "            multimask_output=False\n",
                "        )\n",
                "        all_masks.append(masks[0])\n",
                "    \n",
                "    # Save combined mask\n",
                "    combined_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
                "    for i, mask in enumerate(all_masks):\n",
                "        combined_mask[mask] = i + 1\n",
                "    \n",
                "    mask_path = f\"{OUTPUT_FOLDER}/masks/{img_file.rsplit('.', 1)[0]}_mask.png\"\n",
                "    cv2.imwrite(mask_path, combined_mask)\n",
                "    \n",
                "    # Save visualization\n",
                "    vis_image = image.copy()\n",
                "    for mask in all_masks:\n",
                "        color = np.random.randint(0, 255, 3).tolist()\n",
                "        vis_image[mask] = vis_image[mask] * 0.5 + np.array(color) * 0.5\n",
                "    \n",
                "    vis_path = f\"{OUTPUT_FOLDER}/visualizations/{img_file}\"\n",
                "    cv2.imwrite(vis_path, vis_image)\n",
                "    \n",
                "    print(f\"{img_file}: {len(boxes)} objects segmented\")\n",
                "\n",
                "print(f\"\\nDone! Results saved to {OUTPUT_FOLDER}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Output\n",
                "\n",
                "- `masks/` - Binary mask images for each input image\n",
                "- `visualizations/` - Original images with colored mask overlays"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}